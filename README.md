A trying program of non autoregressive image captioning.

Transforemer Encoder outputs is upsampled and used for input as Transformer Decoder target input. And, CTCLoss was used for calculation of loss.

### Inference Results


![InferenceResult](https://github.com/toshiouchi/non_autoregressive_transformer_image_captioning/assets/121741811/f3f9ff42-3928-41f8-9c3d-e30b352f9194)


## Link
### Only Mask-Predict
https://github.com/toshiouchi/ImageCaptioningMaskPredict

### CTC + Mask-Predict
https://github.com/toshiouchi/CTCMask/blob/main/README.md
